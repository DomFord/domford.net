---
title: "Communicative artificial intelligence for nonplayer characters in digital games: Mapping the field"
authors:
- admin
date: "2025-07-03"
publishDate: "2025-07-03T10:12:56.981268Z"
publication_types: ["speech"]
abstract: "I map the current state of the field both in terms of research and applications. What has been done, what are researchers writing about it, and what are they not writing about it? Then I briefly lay out a potential fruitful area of theoretical discussion: the philosophy of fiction. I show how we can draw on critical insights from existing research on AI in other domains. I end with a call for further critical, theoretical research coming from the our various disciplines and intersections within game studies on this topic."
tags:

---

Presented at the 2025 DiGRA International Conference: Games at the Crossroads, Valletta, Malta, 30 June–4 July.

# Extended abstract

It’s a utopian vision for games: endlessly talk to nonplayers characters (NPCs), freely, about anything, and have them respond in-character directly to your specific utterance, unshackled from the limitations of a script. Such a vision is closer to reality, some believe, with the help of recent advances in large language models (LLMs), exemplified in applications like ChatGPT. Andrea L. Guzman and Seth C. Lewis call applications like ChatGPT communicative AI, AIs “designed to carry out specific tasks within the communication process that were formerly associated with humans” (2020, 72).

Much of the critical academic research focus has been on the impacts of communicative AIs in other communicative arenas, such as higher education (Playfoot, Quigley, and Thomas 2024), public health (Biswas 2023) and dating (Hou, Leach, and Huang 2024). So far, less research has focused critically on the role of communicative AIs in digital games. The research that exists (see Sweetser 2024) is primarily focused on technical and design challenges, even within game narrative and NPC dialogue. Little research has considered the critical or theoretical implications of communicative AI in game design, even in its most prominent sphere of use: NPC dialogue.

Andreas Hepp et al. argue that, in principle, communicative AI:

(1)	is based on various forms of automation designed for the central purpose of communication,
(2)	is embedded within digital infrastructures, and
(3)	is entangled with human practices. (2023, 48)

When research does not thoroughly engage with especially that third point, how it is entangled with human practices, then we miss a vital aspect: “the processing of these systems cannot be understood beyond human practice” (Hepp et al. 2023, 49). Entanglement here refers to Karen Barad: “individuals do not pre-exist their interactions; rather, individuals emerge through and as part of their entangled intra-relating” (2006, ix). Communicative AI is entangled in both use and production, as LLMs are trained on real human communication. Therefore, we should not consider these as novel, separate technologies, but as developments deeply intertwined with our past and present communication. Hepp et al. argue that this is how we avoid buying into the hype of generative AI ourselves: “we should take note of the hype insofar as it may stand for a fundamental change in the ways we all communicate” (Hepp et al. 2023, 53). I argue that the use of communicative AI in NPC dialogue may constitute such a fundamental change, and so deserves critical attention.

Here, then, I map the current state of the field both in terms of research and applications. What has been done, what are researchers writing about it, and what are they not writing about it? Then I briefly lay out a potential fruitful area of theoretical discussion: the philosophy of fiction. I show how we can draw on critical insights from existing research on AI in other domains. I end with a call for further critical, theoretical research coming from the our various disciplines and intersections within game studies on this topic.

Communicative AI for NPCs is not new. Perhaps the earliest example was Façade (Mateas and Stern 2005), which uses natural language processing in conjunction with a “drama manager” that manages story beats (Mateas and Stern 2003, 7). But, by their own admission, Façade is “a 20 minute one-act play replayable 6 or 7 times before it is exhausted” (2003, 4). More recent applications using newer LLM technology boast loftier ambitions. A popular mod for The Elder Scrolls V: Skyrim (Bethesda Game Studios 2011), Mantella, promises to “bring every NPC to life with AI” (ArtFromTheMachine 2023). Inworld Origins (Inworld AI 2023), a tech demo, puts AI NPCs at the core of the game as witnesses that the player, as a detective, can question. Or consider AI Dungeon (Latitude 2019), which uses GPT-3 (originally GPT-2) to generate a text adventure roleplaying game.

These three examples constitute three important use cases for communicative AI. Mantella demonstrates AI’s addition to an older game via mods; Inworld Origins is a demo game intended to show the power of the technology with AI NPCs at the core of the game; and AI Dungeon is a retail game for which the entire gameworld, including NPCs, is generated.

These three examples could point to fundamental shifts regarding how we communicate with gameworlds and NPCs, such that they pose new challenges to existing theory. For instance, the philosophy of fiction and its application to digital games. As an example, Nele Van de Mosselaer and Stefano Gualeni (2023) introduce the implied designer, a “conceptualization of a designer that the player constructs” to whom “the player ascribes all the intentions that they think underpin the creation of that particular game” (2023, 76). Players make sense of gameworlds at least in part based on what intentions they perceive as being behind their artificial construction. How do AI-generated NPC dialogues affect this? On the one hand, far from making the gameworld “come alive”, it could kill it by removing or at least clouding that aspect of intentionality that is crucial to our making sense of it. On the other hand, we may just need to better conceptualise what specific role the AI is playing. In a forthcoming paper, Yuqian Sun and Stefano Gualeni (Forthcoming) use the metaphors of puppet and actor, arguing that while they attribute more agency to AI actors in general, even in the metaphor of a puppet we can see the intentionality of the puppet master behind it. That is, we may still see the salient intentionality in the restrictions, affordances and guardrails of any given communicative AI model, even if human intentionality is a step further removed.

Further critical and theoretical research in this vein is needed if we are to understand how the experience of playing games shapes and is shaped by advances in communicative AI technology. Industry giants like Ubisoft have already shown great interest in the technology, so it is only a matter of time before such NPCs are commonplace in mainstream digital games. Let’s not wait until the horse has bolted.

# References

ArtFromTheMachine. 2023. “Mantella: Bring NPCs to Life with AI.” *Nexus Mods*. https://www.nexusmods.com/skyrimspecialedition/mods/98631

Barad, Karen. 2006. *Meeting the Universe Halfway: Quantum Physics and the Entanglement of Matter and Meaning*. Durham, NC: Duke University Press. https://doi.org/10.1215/9780822388128

Bethesda Game Studios. 2011. *The Elder Scrolls V: Skyrim*. PC game. Bethesda Softworks.

Biswas, Som S. 2023. “Role of Chat GPT in Public Health.” Annals of Biomedical *Engineering* 51 (5): 868–69. https://doi.org/10.1007/s10439-023-03172-7.

Guzman, Andrea L, and Seth C Lewis. 2020. “Artificial Intelligence and Communication: A Human–Machine Communication Research Agenda.” *New Media & Society* 22 (1): 70–86. https://doi.org/10.1177/1461444819858691.

Hepp, Andreas, Wiebke Loosen, Stephan Dreyer, Juliane Jarke, Sigrid Kannengießer, Christian Katzenbach, Rainer Malaka, Michaela Pfadenhauer Pfadenhauer, Cornelius Puschmann, and Wolfgang Schulz. 2023. “ChatGPT, LaMDA, and the Hype around Communicative AI: The Automation of Communication as a Field of Research in Media and Communication Studies.” *Human-Machine Communication* 6 (July): 41–63. https://doi.org/10.30658/hmc.6.4.

Hou, Haonan, Kevin Leach, and Yu Huang. 2024. “ChatGPT Giving Relationship Advice – How Reliable Is It?” *Proceedings of the International AAAI Conference on Web and Social Media* 18 (May): 610–23. https://doi.org/10.1609/icwsm.v18i1.31338.

Inworld AI. 2023. *Inworld Origins*. PC game. Inworld AI.

Latitude. 2019. *AI Dungeon*. PC game. Latitude.

Mateas, Michael, and Andrew Stern. 2003. “Façade: An Experiment in Building a Fully-Realized Interactive Drama.” Presented at the Game Developers Conference, San Jose, CA. https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=a5d2af2a518e2c74761bdc3d976657ac48c9d2f8.

———. 2005. *Façade*. PC game. Procedural Arts. https://hdl.handle.net/1813/2463.

Playfoot, David, Martyn Quigley, and Andrew G. Thomas. 2024. “Hey ChatGPT, Give Me a Title for a Paper about Degree Apathy and Student Use of AI for Assignment Writing.” *The Internet and Higher Education*, April. https://doi.org/10.1016/j.iheduc.2024.100950.

Sweetser, Penny. 2024. “Large Language Models and Video Games: A Preliminary Scoping Review.” In *ACM Conversational User Interfaces 2024*. Luxembourg: ACM. https://doi.org/10.1145/3640794.3665582.

Sun, Yuqian, and Stefano Gualeni. Forthcoming. “Between Puppet and Actor: Reframing Authorship in This Age of AI Agents.”

Van de Mosselaer, Nele, and Stefano Gualeni. 2023. “The Implied Designer of Digital Games.” *Estetika: The European Journal of Aesthetics* LX/XVI (1): 71–89. https://doi.org/10.33134/eeja.303.